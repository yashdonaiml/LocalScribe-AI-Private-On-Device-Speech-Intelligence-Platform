# LLM API Configuration (OpenAI-compatible)
# This app works with ANY OpenAI API-compatible provider!

# Ollama (default in devcontainer - runs as separate Docker service)
LLM_BASE_URL=http://ollama:11434/v1
LLM_API_KEY=ollama  # Required but ignored by Ollama
LLM_MODEL=gemma3:4b

# Examples for other providers:
# LM Studio: LLM_BASE_URL=http://localhost:1234/v1, LLM_API_KEY=lm-studio, LLM_MODEL=your-model

# Whisper Configuration (local speech-to-text)
WHISPER_MODEL=base.en
